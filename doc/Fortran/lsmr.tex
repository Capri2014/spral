\packagename{LSMR}
\version{1.0.0}
\versiondate{19 February 2016}
\purpose{
   This package uses the LSMR iterative method to solve sparse linear 
equations and sparse least-squares
problems of the form:
\[ \begin{array}{ll}
 \mbox{1. Nonsymmetric equations:} & \mbox{minimize  } \|x\|_2 \mbox{  subject to }Ax = b, \\
 \mbox{2. Linear least squares:} & \mbox{minimize  } \|Ax - b\|_2^2 ,\\
\mbox{3. Regularized least squares:} & \mbox{minimize  } \|Ax - b\|_2^2 + \lambda^2\|x\|_2^2 , 
\end{array}
\]
where the $m \times n$ matrix $A$ may be square or rectangular, and may have any rank.
The scalar $\lambda$ is a damping parameter. If $\lambda > 0$, the solution is 
regularized in the sense that a unique soluton always exists,
and $\|x\|_2$ is always bounded.


Preconditioning may be used to try to reduce the number of iterations. 
A suitable choice for the preconditioner depends on the user's knowledge of $A$. 
For a user-chosen $n \times n$ nonsingular matrix $P$,  LSMR solves 
\[ \begin{array}{ll}
 \mbox{1. Nonsymmetric equations:} & \mbox{minimize  } \|Py\|_2 \mbox{  subject to }APy = b, \\
 \mbox{2. Linear least squares:} & \mbox{minimize  } \|APy - b\|_2^2 ,\\
\mbox{3. Regularized least squares:} & \mbox{minimize  } \|APy - b\|_2^2 + \lambda^2\|Py\|_2^2 , 
\end{array}
\]
The user must then recover the final solution $x$ by computing $x=Py$.
$P$ will be a good preconditioner if $AP$ is significantly better conditioned than $A$.


Reverse communication is used for preconditioning
operations $Pz$ and $P^Tz$ and matrix-vector products of the form $Av$ and $A^Tu$.


The method used is based on the Golub-Kahan bidiagonalization process. 
It is algebraically equivalent to applying MINRES to the normal 
equation $(A^TA+\lambda^2I)x=A^Tb$ (or $((AP)^T(AP)+\lambda^2I)y=(AP)^Tb$), but has better numerical properties, 
especially if $A$ is ill-conditioned. 
Note that \texttt{SSIDS} should not be used if $A$ is symmetric.

Details of the algorithm are given in
D.~C.-L. Fong and M.~A. Saunders, {\it LSMR: An iterative algorithm for sparse least-squares problems}, SIAM J. Sci. Comput. 33:5, 2950-2971.
}

\title{LSMR Solver}
\author{
   Nick Gould (STFC Rutherford Appleton Laboratory) \\
   Jennifer Scott (STFC Rutherford Appleton Laboratory)
}
\pkglang{Fortran}
\spralmaketitle
\thispagestyle{firststyle}

\newpage
\section*{Major version history}
\begin{description}
\item[2016-xx-xx Version 1.0.0.] Initial release.
\end{description}

%%%%%%%%%%%%%%%%%%%%%% installation %%%%%%%%%%%%%%%%%%%%%%

\section{Installation}
Please see the SPRAL install documentation. 

%%%%%%%%%%%%%%%%%%%%%% how to use %%%%%%%%%%%%%%%%%%%%%%%%

\section{Usage overview}

\subsection{Calling sequences}

Access to the package requires a {\tt USE} statement \\ \\
\indent\hspace{8mm}{\tt use spral\_LSMR} \\

\medskip

\noindent
The following procedures are available to the user:
\begin{itemize}
\item {\tt LSMR()} uses the LSMR method. It must be called repeatedly
using a reverse communication interface.
\item {\tt LSMR\_free()} should be called after all other calls are complete
to free the memory that has been allocated. 
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%% derived types %%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Derived types}

For each problem, the user must employ the derived types defined by the
package to declare scalars of the types
{\tt LSMR\_options}, {\tt LSMR\_inform}, and {\tt LSMR\_keep}.
The following pseudo-code illustrates this.
\begin{verbatim}
      use spral_LSMR_double
      ...
      type (LSMR_options) :: options
      type (LSMR_inform)  :: inform
      type (LSMR_keep)    :: keep
      ...
\end{verbatim}
The components of {\tt LSMR\_options} and {\tt LSMR\_inform} are explained
in Sections~\ref{LSMR:type:options} and \ref{LSMR:type:inform}.
The components of {\tt LSMR\_keep} are used to pass
data between calls and must not be altered by the user.


\subsection{Optional arguments}

We use square brackets {\tt [ ]} to indicate {\it optional} arguments.
In each
call, optional arguments follow the argument {\tt inform}.  Since we
reserve the right to add additional optional arguments in future
releases of the code, {\bf we strongly recommend that all optional
arguments be called by keyword, not by position}.

\subsection{Integer, real and package types}

{\tt INTEGER} denotes default {\tt INTEGER}.
{\tt REAL} denotes double precision real.
We also use the term {\bf package type} to mean the same.

\subsection{Notation}
In the rest of this documentation, we use the following notation:
    $$ \bar{A}   =  \left( \begin{array}{c} A \\ \lambda I \end{array} \right)P, 
  \hspace{1cm}     \bar{b}   =  \left( \begin{array}{c} b \\ 0 \end{array} \right), $$
    and
     $$r      =  b - APy , \hspace{1cm}        \bar{r}  =  \bar{b} - \bar{A}y,
    \hspace{1cm}  x = Py. $$

%%%%%%%%%%%%%%%%%%%%%% argument lists %%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Argument lists}

\subsection{\texttt{LSMR()}}
\textbf{
   A call of the following form must be made repeatedly}
\vspace{0.2cm}

      \texttt{ \hspace*{0.2cm}
         call LSMR (action, m, n, u, v, y, keep, options, inform [,damp])
      }

\noindent
\begin{description}
\item[\texttt{action}] is an \intentin\ scalar of type {\tt INTEGER}. 
Prior to the first call to {\tt LSMR},
{\tt action} must be set {\tt 0}. On each exit, {\tt action}
indicates the action required by the user. The possible values of {\tt action}
and the action required are as follows:
\begin{description}
\item \texttt{0} The computation has terminated
because an error has occurred (see {\tt inform\%flag}),
or the exact solution is $x=0.0$,  or 
(if {\tt options\%ctest}$=${\tt 3}) convergence has been
achieved.


\item \texttt{1} The user must compute 
$$ v = v + P^TA^Tu  $$ 
without altering $u$, and then re-call the subroutine. 
The vectors $u$ and $v$ are held in {\tt u} and {\tt v}, respectively.

\item \texttt{2} The user must compute 
$$ u = u + APv  $$ 
 without altering $v$, and then re-call the subroutine. 
The vectors $u$ and $v$ are held in  {\tt u} and {\tt v}, respectively.

\item \texttt{3}  The user may test
for convergence. If the user does not wish
to test for convergence or if convergence has not been achieved, the user
should recall the subroutine without changing any of the arguments.
Note that {\tt action}$ =${\tt 3} is never returned if 
{\tt options\%ctest}$=${\tt 3}.

\end{description}

\item[\texttt{m}] is an \intentin\ scalar of type {\tt INTEGER} that must hold 
the row dimension of $A$. {\bf Restriction:} {\tt m}$ \ge 1$.

\item[\texttt{n}] is an \intentin\ scalar of type {\tt INTEGER} that must hold 
the columns dimension of $A$.  {\bf Restriction:} {\tt n}$ \ge 1$.

\item[\texttt{u}] is an \intentinout\ rank-one array of package type 
and size {\tt m}. Prior to the first call, {\tt u} must hold the vector $b$.
{\tt u} is then used for reverse communication.

\item[\texttt{v}] is an \intentinout\ rank-one array of package type 
and size {\tt n}. {\tt v} is used for reverse communication.


\item[\texttt{y}] is an \intentinout\ rank-one array of package type 
and size {\tt n}. It must not be changed by the user between calls.
{\tt y} is used to hold the computed solution $y$ of the
preconditioned problem. The user can recover the required solution $x$ by computing
$x = Py$.

\item[\texttt{keep}] is an \intentinout\ scalar of type
{\tt LSMR\_keep}. It is used to hold data about the problem being
solved and must not be changed by the user.

\item[\texttt{options}] is an \intentin\ scalar of type {\tt LSMR\_options}.
Its components specify the algorithmic options used by the routine, as
explained in Section~\ref{LSMR:type:options}.

\item[\texttt{inform}] is an \intentinout\ scalar of type
{\tt LSMR\_inform}. Its components provide information about the execution
of the routine, as explained in Section~\ref{LSMR:type:inform}.
It must not be changed by the user.

\item[\texttt{damp}] is an optional \intentin\ scalar of type
{\tt REAL}. If present, it must hold the damping parameter $\lambda$.

\end{description}


%%%%%%% termination subroutine %%%%%%

\subsection{\texttt{LSMR\_free()}}
\textbf{To free memory a single call must be made}
\vspace{0.2cm}

       \texttt{ \hspace*{0.2cm}
         call LSMR\_free(keep, stat)
      }
\vspace{0.2cm}

\noindent
Once all  calls to \texttt{LSMR()} are complete,
a call should be made to free memory  allocated by
\texttt{LSMR()}  associated with the derived data type {\tt keep}.
Note that, if a series of problems is being solved sequentially, the same {\tt keep}
may be used for them all and {\tt LSMR\_free()} needs to be called only
after the final problem has terminated.

\begin{description}

\item[\texttt{keep}] is an \intentinout\ scalar  of type {\tt LSMR\_keep}
that must be passed unchanged.
On exit, allocatable components will have been deallocated.

\item[\texttt{stat}] is an \intentout\ scalar of type {\tt INTEGER}.
On successful exit, it is set to zero. Otherwise, it holds the Fortran stat
parameter and indicates the deallocation of one or more components of
{\tt keep} was unsuccessful.

\end{description}



%%%%%%%%%%% options type %%%%%%%%%%%

\section{Derived types}
\subsection{\texttt{LSMR\_options}}
\label{LSMR:type:options}

The derived data type {\tt LSMR\_options} is used to specify the options used
within \texttt{LSMR}. The components are automatically
given default values in the definition of the type.

%%%%%%%%%%%%
\subsubsection*{Printing options}

\begin{description}

\item[\texttt{print\_freq\_head}] is a scalar of type  {\tt INTEGER}
that is used to control the frequency of printing 
of heading information (that is, how many
lines are printed before the heading information is reprinted). 
The default is {\tt print\_freq\_head$=$\tt 20}.

\item[\texttt{print\_freq\_itn}] is a scalar of type  {\tt INTEGER}
that is used to control the frequency of printing.
There is printing on each of the first {\tt print\_freq\_itn} iterations 
and then printing  every {\tt print\_freq\_itn}
iterations.
The default is {\tt print\_freq\_$=$\tt 10}.



\item[\texttt{unit\_diagnostics}] is a scalar  of type
{\tt INTEGER} that holds the
unit number for diagnostic printing. Printing is suppressed if
{\tt unit\_diagnostics$<0$}.
The default is {\tt unit\_diagnostics$=$6}.

\item[\texttt{unit\_error}] is a scalar of type  {\tt INTEGER} that holds the
unit number for error messages.
Printing of error messages
is suppressed if {\tt unit\_error$<$0}.
The default is {\tt unit\_error$=$6}.


\end{description}



%%%%%%%%%%%%
\subsubsection*{Other options}

\begin{description}




\item[\texttt{atol}] is a scalar of type {\tt REAL} that is only used if {\tt options\%ctest}$ =${\tt 3}.
    In which case, it must hold an estimate of the relative error in the data
    defining the matrix $A$.  For example, if $A$ is accurate to about 6 digits,
    set {\tt atol} to {\tt 1.0d-6}. The default value is {\tt sqrt(epsilon(1.0d0))}.

\item[\texttt{btol}] is a scalar of type {\tt REAL} that is only used if {\tt options\%ctest}$ =${\tt 3}.
     In which case, it must hold an estimate of the relative error in the data
    defining the right-hand side vector $ b$.  For example, if $b$ is
    accurate to about 6 digits, set {\tt btol} to {\tt 1.0d-6}. The default value is 
    {\tt sqrt(epsilon(1.0d0))}.


\item[\texttt{conlim}] is a scalar of type {\tt REAL} that is only used if {\tt options\%ctest}$ =${\tt 3}.
     In which case, it must hold an upper limit on $cond(\bar{A})$, the apparent
     condition number of the matrix $\bar{A}$. Iterations will be terminated 
     if a computed estimate of $cond(\bar{A})$ exceeds {\tt conlim}.
     This is intended to prevent certain small or
     zero singular values of $A$ or $\bar{A}$ from
     coming into effect and causing unwanted growth in the computed solution.
     normally, conlim should be in the range 1000 to 1/$\epsilon$.
     The default value is {\tt 1/(10 sqrt(epsilon(1.0d0))}.

\item[\texttt{ctest}] is a scalar of
type {\tt INTEGER} that is use to control convergence testing. Possible values are:
\begin{description}
\item[\texttt{1}] The user may test for convergence whenever 
          {\tt action}$ = ${\tt 3} is returned; this is
          every {\tt options\%itn\_test} iterations.
          {\tt LSMR()} does {\bf not} compute components
          {\tt normAP}, {\tt condAP}, {\tt normr}, {\tt normAPr}, {\tt normy}
          of the derived type {\tt LSMR\_inform}.
         {\tt LSMR()} will only terminate if an  error is flagged
          or the exact solution is {\tt x}$ = ${\tt 0.0}.
          Thus the user is responsible for determining when to stop.
\item[\texttt{2}] As {\texttt 1} but the components
          {\tt normAP}, {\tt condAP}, {\tt normr}, {\tt normAPr}, {\tt normy}
          of the derived type {\tt LSMR\_inform} hold the latest estimates and may be used
          by the user to decide whether convergence has been achieved.
\item[\texttt{3}] {\tt LSMR()} determines if convergence has been achieved using 
          the stopping criteria of Fong and Saunders. The components
          {\tt normAP}, {\tt condAP}, {\tt normr}, {\tt normAPr}, {\tt normy}
          of the derived type {\tt LSMR\_inform} hold the latest estimates.
          If $P \neq I$,  convergence is tested in the
          preconditioner norm.
\end{description}
The default value is {\tt 3}.

   \item[\texttt{itnlim}] is a scalar of
    type {\tt INTEGER} that holds an upper limit on the number of iterations.
    It has default value {\tt -1}, in which case the 
    maximum number of iterations allowed is $4n$. 

   \item[\texttt{itn\_test}] is a scalar of
    type {\tt INTEGER} that holds the number of iterations that are performed
    between returns with {\tt action}$ = ${\tt 3} (that is, {\tt itn\_test}
    controls how frequently the user may test for convergence).
    {\tt itn\_test} is not used if {\tt options\%ctest}$=${\tt 3}.
The default value is {\tt -1}, in which case the frequency of testing is 
every $\min(n,10)$ iterations.

   \item[\texttt{localSize}] is a scalar of
type {\tt INTEGER} that holds the number of vectors for local reorthogonalization.
It has default values {\tt 0}, in which case no reorthogonalization is performed.
 If {\tt localSize}$>${\tt0}, this many $n$-vectors  (the most recent ones)
are saved for reorthogonalizing the next basis vector.
 {\tt localSize} need not be more than $\min(m,n)$.
 $\min({\tt localSize},m,n)$ vectors of size $n$ are allocated within {\tt keep}.
   

\end{description}

%%%%%%%%%%% inform type %%%%%%%%%%%

\subsection{\texttt{LSMR\_inform}}
\label{LSMR:type:inform}
The derived data type {\tt LSMR\_inform}
is used to hold parameters that give information about the progress and needs
of the algorithm. The components of {\tt LSMR\_inform}
(in alphabetical order) are:

\begin{description}

\item[\texttt{condAP}]  is a scalar of package type that
     only holds information if {\tt options\%ctest}$ =${\tt 2} or {\tt 3}.
     In this case, it holds an estimate of $cond(\bar{A})$, the condition
     number of $\bar{A}$.  A very high value of {\tt condAP}
     may again indicate an error in the products 
     with $A$, $A^T$, $P$, or $P^T$. A negative value indicates
     that no estimate is currently available.

\item[\texttt{flag}] is a scalar of type  {\tt INTEGER}
that gives the exit status of the algorithm (details in Section \ref{LSMR:errors}).

\item[\texttt{itn}] is a scalar of type  {\tt INTEGER} that holds the number
of iterations performed.

\item[\texttt{normAP}]  is a scalar of package type that
     only holds information if {\tt options\%ctest}$ =${\tt 2} or {\tt 3}.
     In this case, it holds an estimate of the Frobenius norm of $\bar{A}$.
     This is the square-root of the sum of squares of the elements of $\bar{A}$.
     If $\lambda$ is small and the columns of $AP$ have all been scaled to have 
     length 1.0, {\tt normAP} should increase to roughly $\sqrt{n}$.
     A radically different value for {\tt normAP} may
     indicate an error in the user-supplied
     products with $A$, $A^T$, $P$, or $P^T$. A negative value
     indicates that no estimate is currently available.

\item[\texttt{normAPr}]  is a scalar of package type that
     only holds information if {\tt options\%ctest}$ =${\tt 2} or {\tt 3}.
     In this case, it holds an estimate of the  value of
     $\| \bar{A}^T\bar{r}\|_2$, the norm of the residual for the normal equations.
     This should be small in all cases.  Note that {\tt normAPr}  will often be smaller 
     than the true value computed from the output vector {\tt y}. A negative value
     indicates that no estimate is currently available.
    
\item[\texttt{normr}] is a scalar of package type that
     only holds information if {\tt options\%ctest}$ =${\tt 2} or {\tt 3}.
     In this case, it holds an estimate of the  value of $\|\bar{r}\|_2$.
     This will be small if $Ax = b$ has a solution. A negative value
     indicates that no estimate is currently available.
    
\item[\texttt{normy}] is a scalar of package type that
     only holds information if {\tt options\%ctest}$ =${\tt 2} or {\tt 3}.
     In this case, it holds estimate of  $\|y\|_2$ for the  solution $y$
     of the preconditioned problem.
     A negative value indicates that no estimate is currently available.

\item[\texttt{stat}] is a scalar of type  {\tt INTEGER} that is used to hold the
Fortran stat parameter.

\end{description}


%%%%%%%%%%%%%%%%%%%%%% Warning and error messages %%%%%%%%%%%%%%%%%%%%%%%%

\section{Return codes} \label{LSMR:errors}

{\tt inform\%flag} is used to hold
information on each return from {\tt LSMR}. 
Possible values are:
\begin{description}
\item{\tt 0 }    $x = 0.0$  is the exact solution.
                   No iterations were performed.
\item{\tt 1 }           The equations $Ax = b$ are probably compatible.
                        $\|Ax - b\|_2$ is sufficiently small, given the
                        values of {\tt options\%atol} and {\tt options\%btol}. 
                        ({\tt options\%ctest}$ = ${\tt 3} only). 
    
\item{\tt 2 }       If {\tt damp} is not present or is zero then the system $Ax = b$ is probably
                     not compatible.  A least-squares solution has
                     been obtained that is sufficiently accurate,
                     given the value of {\tt options\%atol}.  
                     Otherwise, damped least-squares
                        solution has been obtained that is sufficiently
                        accurate, given the value of {\tt options\%atol}. 
                        ({\tt options\%ctest}$ = ${\tt 3} only). 
    
\item{\tt 3 }       An estimate of {\tt cond($\bar{A}$)} has exceeded {\tt options\%conlim}.
                        The system $Ax = b$ appears to be ill-conditioned,
                        or there could be an error in the products 
                        with $A$, $A^T$, $P$, or $P^T$.
                        ({\tt options\%ctest}$ = ${\tt 3} only). 
    
\item{\tt 4 }      $\|APy - b \|_2$ is small enough for this machine.
                        ({\tt options\%ctest}$ = ${\tt 3} only). 
    
\item{\tt 5 }       The least-squares solution is good enough for this
                        machine. ({\tt options\%ctest}$ = ${\tt 3} only). 
    
\item{\tt 6 }       The estimate {\tt inform\%condAP} appears to be too large 
                        for this machine.         
                        ({\tt options\%ctest}$ = ${\tt 3} only). 


\item{\tt 7 }       The iteration limit {\tt options\%itnlim} has been reached. 
\item{\tt 8 }       An array allocation failed.
\item{\tt 9 }       An array deallocation failed.
\item{\tt 10 }      Either  {\tt m$<$0} or {\tt n$<$0} (first call only).

\end{description}

\section{Method} \label{method}

\subsection{Algorithm}
The method used is based on the Golub-Kahan bidiagonalization process. 
It is algebraically equivalent to applying MINRES to the normal 
equation $(A^TA+\lambda^2I)x=A^Tb$ (or $((AP)^T(AP)+\lambda^2I)y=(AP)^Tb$,
$Py = x$,
if preconditioning is used), but has better numerical properties, 
especially if $A$ is ill-conditioned. 
Full details may be found in
{\url{
http://web.stanford.edu/group/SOL/software/lsmr/LSMR-SISC-2011.pdf}}.

\subsection{Scaling}
     LSMR uses an iterative method to approximate the solution.
     The number of iterations required to reach a certain accuracy
     depends strongly on the scaling of the problem.  Poor scaling of
     the rows or columns of $A $ should therefore be avoided where
     possible. For example, in problem 1 the solution is unaltered by
     row-scaling.  If a row of $A$ is very small or large compared to
     the other rows of $A$, the corresponding row of $ ( A\;  b )$ should be
     scaled up or down.
    
     In problems 1 and 2, the solution $x$ is easily recovered
     following column-scaling.  Unless better information is known,
     the nonzero columns of $A$ should be scaled so that they all have
     the same Euclidean norm (e.g., 1.0).
     In problem 3, there is no freedom to re-scale if damp is
     nonzero.  However, the value of {\tt damp} should be assigned only
     after attention has been paid to the scaling of $A$.
    
     The parameter {\tt damp} is intended to help regularize
     ill-conditioned systems, by preventing the true solution from
     being very large.  Another aid to regularization is provided by
     the {\tt inform\%condAP}, which may be used to terminate iterations
     before the computed solution becomes very large.

\subsection{Initial estimate}
    
     Note that $x$ (or $y$ for the preconditioned problem) is not an input parameter.
     If some initial estimate $x_0$ of $x$ is known and if $\lambda = 0$,
     one could proceed as follows:
    \begin{itemize} 
     \item 1. Compute a residual vector     $r_0 = b - Ax_0$.
    \item 2. Use LSMR to solve the system  $A \delta x = r_0$.
    \item 3. Add the correction $\delta x$ to obtain a final solution $x = x_0 + \delta x$.
    \end{itemize}
     This can be generalized for the preconditioned case.
     The guess $x_0$ has to be available before and after the calls
     to {\tt LSMR()}.  To judge the benefits, suppose {\tt LSMR()} takes $k_1$ iterations
     to solve $Ax = b$ and $k_2$ iterations to solve $A \delta x = r_0$.
     If $x_0$ is ``good", $\|r_0\|_2$ will be smaller than $\|b\|_2$.
     If the same stopping tolerances {\tt options\%atol} and {\tt options\%btol}
      are used for each
     system, $k_1$ and $k_2$ will be similar, but the final solution $x = x_0 + \delta x$
     should be more accurate.  The only way to reduce the total work
     is to use a larger stopping tolerance for the second system.
     If some value {\tt options\%btol} is suitable for $Ax=b$, the larger value
     {\tt options\%btol}*$\|b\|_2$/$\|r_0\|_2$  should be suitable for $A \delta x = r_0$.
    



%%%%%%%%%%%%%%%%%%%%%% EXAMPLE %%%%%%%%%%%%%%%%%%%%%%%%

\section{Example}
The following code illustrates the use of LMSR

\begin{verbatim}

program spral_lsmr_example
    use  spral_lsmr
    implicit none
  
    integer, parameter :: wp = kind( 1.0d+0 )

    type ( lsmr_keep )    :: keep 
    type ( lsmr_options ) :: options
    type ( lsmr_inform )  :: inform

    integer :: ptr(4), row(9)
    real(wp) :: b(5), u(5), v(3), val(9), x(3)

    integer :: action, m, n, stat

    ! Data for matrix:
    ! ( 1.0     -1.0 )
    ! (     2.0      )
    ! ( 2.0      2.0 )
    ! ( 5.0 3.0 -2.0 )
    ! (          6.0 )
    m = 5; n = 3
    ptr(1:n+1)        = (/ 1,               4,         6,                 10 /)
    row(1:ptr(n+1)-1) = (/ 1,     3,   4,   2,   4,    1,   3,    4,   5 /)
    val(1:ptr(n+1)-1) = (/ 1.0, 2.0, 5.0, 2.0, 3.0, -1.0, 2.0, -2.0, 6.0 /)
    ! Data for rhs b
    b(1:m) = (/ 1.0, 1.0, 1.0, 1.0, 1.0 /)

    ! prepare for LSMR calls (using no preconditioning and default
    ! settings, except switch off diagnostic printing)
    options%unit_diagnostics = -1
    action = 0
    u(1:m) = b(1:m)

    do

       call LSMR(action, m, n, u, v, x, keep, options, inform)

       if (action.eq.0) then
          ! we are done.
          write (*,'(a,i3,a,i3)') ' Exit LSMR with inform%flag = ',inform%flag,&
            ' and inform%itn = ',inform%itn
          write (*,'(a)') ' LS solution is in x(1:n)'
          exit

      else if (action.eq.1) then

            ! Compute v = v + A'*u without altering u
             call matrix_mult_trans(m,n,ptr,row,val,u,v)

      else if (action.eq.2) then

            ! Compute u = u + A*v  without altering v
            call matrix_mult(m,n,ptr,row,val,v,u)

      end if

   end do

   call LSMR_free(keep,stat)

  contains
!**************************************************************
      ! Takes b and computes u = u + A * v (A in CSC format)

      subroutine matrix_mult(m,n,ptr,row,val,v,u)

      integer,  intent(in) :: m,n
      integer,  intent(in) :: ptr(n+1),row(:)
      real(wp), intent(in) :: val(:),v(n)
      real(wp), intent(inout) :: u(m)

      integer:: i,j,k
      real(wp) :: temp
    
         do j = 1,n
            temp = v(j)
            do k = ptr(j),ptr(j+1)-1
                i = row(k)
                u(i) = u(i) + val(k)*temp
            end do
         end do

      end subroutine matrix_mult

!**************************************************************
      ! Takes b and computes v = v + A^T * u (A in CSC format)

      subroutine matrix_mult_trans(m,n,ptr,row,val,u,v)

      integer,  intent(in) :: m,n
      integer,  intent(in) :: ptr(n+1),row(:)
      real(wp), intent(in) :: val(:),u(m)
      real(wp), intent(inout) :: v(n)

      integer:: i,j,k
      real(wp) :: sum
      
         do j = 1,n
            sum = 0.0_wp
            do k = ptr(j),ptr(j+1)-1
               i = row(k)
               sum = sum + val(k)*u(i)
            end do
            v(j) = v(j) + sum
         end do

      end subroutine matrix_mult_trans

end program spral_lsmr_example
\end{verbatim}


This returns the following output:

\begin{verbatim}
 Exit LSMR with inform%flag =   2 and inform%itn =   3
 LS solution is in x(1:n)
\end{verbatim}

\begin{funders}
   \funder{epsrc}{Funded by EPSRC grant EP/MO25179/1}
\end{funders}
