\packagename{LSMR}
\version{1.0.0}
\versiondate{19 February 2016}
\purpose{
   This package uses the LSMR iterative method to solve sparse linear 
   equations and sparse least-squares
   problems of the form:
   $$
   \begin{array}{ll}
      \mbox{1. Nonsymmetric equations:} &
         \mbox{minimize } \|x\|_2 \mbox{ subject to }Ax = b, \\
      \mbox{2. Linear least squares:} & \mbox{minimize  } \|Ax - b\|_2^2,\\
      \mbox{3. Regularized least squares:} &
         \mbox{minimize  } \|Ax - b\|_2^2 + \lambda^2\|x\|_2^2, 
   \end{array}
   $$
   where the $m \times n$ matrix $A$ may be square or rectangular, and may have
   any rank. The scalar $\lambda$ is a damping parameter. If $\lambda > 0$, the
   solution is regularized in the sense that a unique soluton always exists,
   and $\|x\|_2$ is always bounded.

   Preconditioning may be used to try to reduce the number of iterations. 
   A suitable choice for the preconditioner depends on the user's knowledge of
   $A$. For a user-chosen $n \times n$ nonsingular matrix $P$,  LSMR solves
   $$
   \begin{array}{ll}
      \mbox{1. Nonsymmetric equations:} &
         \mbox{minimize  } \|Py\|_2 \mbox{  subject to }APy = b, \\
      \mbox{2. Linear least squares:} & \mbox{minimize  } \|APy - b\|_2^2 ,\\
      \mbox{3. Regularized least squares:} &
         \mbox{minimize  } \|APy - b\|_2^2 + \lambda^2\|Py\|_2^2 , 
   \end{array}
   $$
   The user must then recover the final solution $x$ by computing $x=Py$.
   $P$ will be a good preconditioner if $AP$ is significantly better conditioned
   than $A$.

   Reverse communication is used for preconditioning operations $Pz$ and $P^Tz$
   and matrix-vector products of the form $Av$ and $A^Tu$.

   The method used is based on the Golub-Kahan bidiagonalization process. 
   It is algebraically equivalent to applying MINRES to the normal 
   equation $(A^TA+\lambda^2I)x=A^Tb$ (or $((AP)^T(AP)+\lambda^2I)y=(AP)^Tb$),
   but has better numerical properties, especially if $A$ is ill-conditioned. 
   Note that \texttt{SSIDS} should not be used if $A$ is symmetric.

   Details of the algorithm are given in
   D.~C.-L. Fong and M.~A. Saunders, {\it LSMR: An iterative algorithm for
   sparse least-squares problems}, SIAM J. Sci. Comput. 33:5, 2950-2971.
}

\title{LSMR Solver}
\author{
   Nick Gould (STFC Rutherford Appleton Laboratory) \\
   Jennifer Scott (STFC Rutherford Appleton Laboratory)
}
\pkglang{C}
\spralmaketitle
\thispagestyle{firststyle}

\newpage
\section*{Major version history}
\begin{description}
\item[2016-05-10 Version 1.0.0.] Initial release.
\end{description}

%%%%%%%%%%%%%%%%%%%%%% installation %%%%%%%%%%%%%%%%%%%%%%

\section{Installation}
Please see the SPRAL install documentation. 

%%%%%%%%%%%%%%%%%%%%%% how to use %%%%%%%%%%%%%%%%%%%%%%%%

\section{Usage overview}

\subsection{Calling sequences}

Access to the package requires inclusion of either \texttt{spral.h} (for the
entire \spral librar) or \texttt{spral\_lsmr.h} (for just the relevant routines)

\begin{verbatim}
   #inlcude "spral.h"
\end{verbatim}

\medskip

\noindent
The following functions are available to the user:
\begin{itemize}
\item {\tt spral\_lsmr\_default\_options()} initializes the \texttt{options}
   structure to default values.
\item {\tt spral\_lsmr()} uses the LSMR method. It must be called repeatedly
   using a reverse communication interface.
\item {\tt spral\_lsmr\_free()} should be called after all other calls are
   complete to free the memory that has been allocated. 
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%% derived types %%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Derived types}

For each problem, the user must employ the derived types defined by the
package to declare scalars of the types
{\tt struct spral\_lsmr\_options}, {\tt struct spral\_lsmr\_inform}. The user
must also
declare a \texttt{void~*} pointer {\tt keep} for the package's private data
structure. The options data structure \textbf{must} be initalized using
\texttt{spral\_lsmr\_default\_options()}, and the pointer \texttt{keep} must be
initialized to \texttt{NULL}.
The following pseudo-code illustrates this.
\begin{verbatim}
      #include "spral.h"
      ...
      struct spral_lsmr_options options;
      struct spral_lsmr_inform inform;
      void *keep = NULL;
      ...
      spral_lsmr_default_options(&options);
\end{verbatim}
The members of {\tt spral\_lsmr\_options} and {\tt spral\_lsmr\_inform} are
explained in Sections~\ref{LSMR:type:options} and \ref{LSMR:type:inform}.
The \texttt{void~*} pointer is allocated using Fortran, and must be passed to
\texttt{spal\_lsmr\_free()} to release the associated memory.

\subsection{Notation}
In the rest of this documentation, we use the following notation:
$$
   \bar{A} = \left( \begin{array}{c}
         A \\
         \lambda I
      \end{array} \right)P, \hspace{1cm} \bar{b} = \left( \begin{array}{c}
         b \\
         0
      \end{array} \right),
$$
and
$$
   r = b - APy , \hspace{1cm}  \bar{r} = \bar{b} - \bar{A}y,
      \hspace{1cm}  x = Py.
$$

%%%%%%%%%%%%%%%%%%%%%% argument lists %%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Argument lists}

\subsection{\texttt{spral\_lsmr\_default\_options()}}
\textbf{To initialise a variable of type \texttt{struct spral\_lsmr\_options},
the following routine is provided.}

\vspace*{0.1cm}
\noindent
\textbf{\texttt{
   \hspace*{0.3cm} void spral\_lsmr\_default\_options(struct spral\_lsmr\_options *options);
}}

\noindent
\begin{description}
   \item[\texttt{*options}] is the instance to be initialized.
\end{description}

\subsection{\texttt{spral\_lsmr()}}
\textbf{
   To perform the LSMR algorithm, a call to the following subroutine must be
   repeated.
   \vspace{0.2cm}\\
   \texttt{
      \hspace*{0.2cm} int lsmr(int *action, int m, int n, double u[], double v[], double y[], void **keep,\\
      \hspace*{0.7cm} struct spral\_lsmr\_options const *options, struct spral\_lsmr\_inform *inform,\\
      \hspace*{0.7cm} double *damp)
   }
}

\noindent
\begin{description}

\item[\texttt{action}] communicates the action to be taken.
Prior to the first call to {\tt spral\_lsmr()},
{\tt action} must be set {\tt 0}. On each exit, {\tt action}
indicates the action required by the user. The possible values of {\tt action}
and the action required are as follows:
\begin{description}
   \item \texttt{0} The computation has terminated
      because an error has occurred (see {\tt inform.flag}),
      or the exact solution is $x=0.0$,  or 
      (if {\tt options.ctest}$=${\tt 3}) convergence has been
      achieved.
   \item \texttt{1} The user must compute 
      $$ v = v + P^TA^Tu  $$ 
      without altering $u$, and then re-call the subroutine. 
      The vectors $u$ and $v$ are held in {\tt u} and {\tt v}, respectively.
   \item \texttt{2} The user must compute 
      $$ u = u + APv  $$ 
      without altering $v$, and then re-call the subroutine. 
      The vectors $u$ and $v$ are held in  {\tt u} and {\tt v}, respectively.
   \item \texttt{3}  The user may test for convergence. If the user does not
      wish to test for convergence or if convergence has not been achieved, the
      user should recall the subroutine without changing any of the arguments.
      Note that {\tt action}$ =${\tt 3} is never returned if 
      {\tt options.ctest}$=${\tt 3}.
\end{description}

\item[\texttt{m}] must hold 
the row dimension of $A$. {\bf Restriction:} {\tt m}$ \ge 1$.

\item[\texttt{n}] must hold 
the columns dimension of $A$.  {\bf Restriction:} {\tt n}$ \ge 1$.

\item[\texttt{u[m]}] is used for communication with the user. Prior to the first call, {\tt u} must hold the vector $b$.
{\tt u} is then used for reverse communication (see description of \texttt{action}.

\item[\texttt{v[n]}] is used for reverse communication (see description of \texttt{action}).


\item[\texttt{y[n]}] is used to hold the computed solution $y$ of the
preconditioned problem. It must not be changed by the user between calls.
The user can recover the required solution $x$ by computing $x = Py$.

\item[\texttt{keep}] is allocated to hold data about the problem being
solved and must not be changed by the user.

\item[\texttt{options}] specifies the algorithmic options used by the routine,
as explained in Section~\ref{LSMR:type:options}.

\item[\texttt{inform}] is used to return information about the execution
of the routine, as explained in Section~\ref{LSMR:type:inform}.
It must not be changed by the user.

\item[\texttt{damp}] may be \texttt{NULL}. If it is non-\texttt{NULL}, it must
hold the damping parameter $\lambda$.

\item[\textbf{Return value}] is \texttt{info.flag}. That is,
\texttt{0} on success, otherwise an error code as described in
Section~\ref{LSMR:errors}.

\end{description}


%%%%%%% termination subroutine %%%%%%

\subsection{\texttt{spral\_lsmr\_free()}}
\textbf{To free memory a single call must be made
   \vspace{0.2cm}\\
    \texttt{ \hspace*{0.2cm}
      int spral\_lsmr\_free(void **keep)
   }
}
\vspace{0.2cm}

\noindent
Once all  calls to \texttt{spral\_lsmr()} are complete,
a call should be made to free memory  allocated by
\texttt{spral\_lsmr()}  associated with the derived data type {\tt keep}.
Note that, if a series of problems is being solved sequentially, the same {\tt keep}
may be used for them all and {\tt spral\_lsmr\_free()} needs to be called only
after the final problem has terminated.

\begin{description}

\item[\texttt{keep}] must be passed unchanged since the last call to \texttt{spral\_lsmr()}.
On exit, internal memory will have been freed and \texttt{*keep}
will be set to \texttt{NULL}.

\item[Return value] is \texttt{0} on success. Otherwise, it is the Fortran
stat parameter for the unsiccessful deallocation.

\end{description}



%%%%%%%%%%% options type %%%%%%%%%%%

\section{Derived types}
\subsection{\texttt{spral\_lsmr\_options}}
\label{LSMR:type:options}

The derived data type {\tt struct spral\_lsmr\_options} is used to specify the
options used by the \texttt{LSMR} algorithm. The data structure must be
initialized by a call to \texttt{spral\_lsmr\_default\_options()}.

%%%%%%%%%%%%
\subsubsection*{Printing options}

\begin{description}

\item[\texttt{int print\_freq\_head}]
is used to control the frequency of printing 
of heading information (that is, how many
lines are printed before the heading information is reprinted). 
The default is {\tt print\_freq\_head$=$\tt 20}.

\item[\texttt{int print\_freq\_itn}]
is used to control the frequency of printing.
There is printing on each of the first {\tt print\_freq\_itn} iterations 
and then printing  every {\tt print\_freq\_itn}
iterations.
The default is {\tt print\_freq\_$=$\tt 10}.



\item[\texttt{int unit\_diagnostics}] holds the Fortran
unit number for diagnostic printing. Printing is suppressed if
{\tt unit\_diagnostics$<0$}.
The default is {\tt unit\_diagnostics$=$6}.

\item[\texttt{int unit\_error}] holds the Fortran
unit number for error messages.
Printing of error messages
is suppressed if {\tt unit\_error$<$0}.
The default is {\tt unit\_error$=$6}.


\end{description}



%%%%%%%%%%%%
\subsubsection*{Other options}

\begin{description}

\item[\texttt{double atol}] is only used if
   {\tt options.ctest}$ =${\tt 3}.
   In which case, it must hold an estimate of the relative error in the data
   defining the matrix $A$.  For example, if $A$ is accurate to about 6 digits,
   set {\tt atol} to {\tt 1.0e-6}. The default value is $\sqrt{\epsilon}$.

\item[\texttt{double btol}] is only used if
   {\tt options.ctest}$ =${\tt 3}.
   In which case, it must hold an estimate of the relative error in the data
   defining the right-hand side vector $b$.  For example, if $b$ is
   accurate to about 6 digits, set {\tt btol} to {\tt 1.0d-6}. The default value
   is the $\sqrt{\epsilon}$.


\item[\texttt{double conlim}] is only used if
   {\tt options.ctest}$ =${\tt 3}.
   In which case, it must hold an upper limit on $cond(\bar{A})$, the apparent
   condition number of the matrix $\bar{A}$. Iterations will be terminated 
   if a computed estimate of $cond(\bar{A})$ exceeds {\tt conlim}.
   This is intended to prevent certain small or
   zero singular values of $A$ or $\bar{A}$ from
   coming into effect and causing unwanted growth in the computed solution.
   normally, conlim should be in the range 1000 to 1/$\epsilon$.
   The default value is $1/(10\sqrt{\epsilon})$.

\item[\texttt{int ctest}] is used to control
   convergence testing. Possible values are:
   \begin{description}
   \item[\texttt{1}] The user may test for convergence whenever 
      {\tt action}$ = ${\tt 3} is returned; this is
      every {\tt options.itn\_test} iterations.
      {\tt spral\_lsmr()} does {\bf not} compute members
      {\tt normAP}, {\tt condAP}, {\tt normr}, {\tt normAPr}, {\tt normy}
      of the derived type {\tt spral\_lsmr\_inform}.
      {\tt spral\_lsmr()} will only terminate if an  error is flagged
      or the exact solution is {\tt x}$ = ${\tt 0.0}.
      Thus the user is responsible for determining when to stop.
   \item[\texttt{2}] As {\texttt 1} but the members
      {\tt normAP}, {\tt condAP}, {\tt normr}, {\tt normAPr}, {\tt normy}
      of the derived type {\tt spral\_lsmr\_inform} hold the latest estimates and
      may be used by the user to decide whether convergence has been achieved.
   \item[\texttt{3}] {\tt spral\_lsmr()} determines if convergence has been achieved
      using the stopping criteria of Fong and Saunders. The members
      {\tt normAP}, {\tt condAP}, {\tt normr}, {\tt normAPr}, {\tt normy}
      of the derived type {\tt spral\_lsmr\_inform} hold the latest estimates.
      If $P \neq I$,  convergence is tested in the
      preconditioner norm.
   \end{description}
   The default value is {\tt 3}.

   \item[\texttt{int itnlim}]
      holds an upper limit on the number of iterations.
      It has default value {\tt -1}, in which case the 
      maximum number of iterations allowed is $4n$. 

   \item[\texttt{int itn\_test}]
      holds the number of iterations that are performed
      between returns with {\tt action}$ = ${\tt 3} (that is, {\tt itn\_test}
      controls how frequently the user may test for convergence).
      {\tt itn\_test} is not used if {\tt options.ctest}$=${\tt 3}.
      The default value is {\tt -1}, in which case the frequency of testing is 
      every $\min(n,10)$ iterations.

   \item[\texttt{int localSize}] holds the
      number of vectors for local reorthogonalization. It has default values
      {\tt 0}, in which case no reorthogonalization is performed.
      If {\tt localSize}$>${\tt0}, this many $n$-vectors  (the most recent ones)
      are saved for reorthogonalizing the next basis vector. {\tt localSize}
      need not be more than $\min(m,n)$. $\min({\tt localSize},m,n)$ vectors of
      size $n$ are allocated within {\tt keep}.
\end{description}

%%%%%%%%%%% inform type %%%%%%%%%%%

\subsection{\texttt{struct spral\_lsmr\_inform}}
\label{LSMR:type:inform}
The derived data type {\tt struct spral\_lsmr\_inform}
is used to hold parameters that give information about the progress and needs
of the algorithm. The members of {\tt spral\_lsmr\_inform}
(in alphabetical order) are:

\begin{description}

\item[\texttt{double condAP}]
   holds information if {\tt options.ctest}$ =${\tt 2} or {\tt 3}.
   In this case, it holds an estimate of $cond(\bar{A})$, the condition
   number of $\bar{A}$.  A very high value of {\tt condAP}
   may again indicate an error in the products 
   with $A$, $A^T$, $P$, or $P^T$. A negative value indicates
   that no estimate is currently available.

\item[\texttt{int flag}] gives the exit
   status of the algorithm (details in Section \ref{LSMR:errors}).

\item[\texttt{int itn}] holds the number
   of iterations performed.

\item[\texttt{double normAP}]
   only holds information if {\tt options.ctest}$ =${\tt 2} or {\tt 3}.
   In this case, it holds an estimate of the Frobenius norm of $\bar{A}$.
   This is the square-root of the sum of squares of the elements of $\bar{A}$.
   If $\lambda$ is small and the columns of $AP$ have all been scaled to have 
   length 1.0, {\tt normAP} should increase to roughly $\sqrt{n}$.
   A radically different value for {\tt normAP} may
   indicate an error in the user-supplied
   products with $A$, $A^T$, $P$, or $P^T$. A negative value
   indicates that no estimate is currently available.

\item[\texttt{double normAPr}] only holds information
   if {\tt options.ctest}$ =${\tt 2} or {\tt 3}. In this case, it holds an
   estimate of the  value of $\| \bar{A}^T\bar{r}\|_2$, the norm of the residual
   for the normal equations. This should be small in all cases.  Note that
   {\tt normAPr}  will often be smaller than the true value computed from the
   output vector {\tt y}. A negative value indicates that no estimate is
   currently available.
    
\item[\texttt{double normr}]
   only holds information if {\tt options.ctest}$ =${\tt 2} or {\tt 3}.
   In this case, it holds an estimate of the  value of $\|\bar{r}\|_2$.
   This will be small if $Ax = b$ has a solution. A negative value
   indicates that no estimate is currently available.
    
\item[\texttt{double normy}]
   only holds information if {\tt options.ctest}$ =${\tt 2} or {\tt 3}.
   In this case, it holds estimate of  $\|y\|_2$ for the  solution $y$
   of the preconditioned problem.
   A negative value indicates that no estimate is currently available.

\item[\texttt{int stat}] is used to hold
   the Fortran stat parameter in the event of an allocation error.

\end{description}


%%%%%%%%%%%%%%%%%%%%%% Warning and error messages %%%%%%%%%%%%%%%%%%%%%%%%

\section{Return codes} \label{LSMR:errors}

{\tt inform.flag} is used to hold
   information on each return from {\tt spral\_lsmr()}. 
Possible values are:
\begin{description}
\item{\tt 0 }  $x = 0.0$  is the exact solution.
               No iterations were performed.
\item{\tt 1 }  The equations $Ax = b$ are probably compatible.
               $\|Ax - b\|_2$ is sufficiently small, given the
               values of {\tt options.atol} and {\tt options.btol}. 
               ({\tt options.ctest}$ = ${\tt 3} only). 
\item{\tt 2 }  If {\tt damp} is not present or is zero then the system $Ax = b$
               is probably not compatible.  A least-squares solution has been
               obtained that is sufficiently accurate, given the value of
               {\tt options.atol}.  
               Otherwise, damped least-squares solution has been obtained that
               is sufficiently accurate, given the value of {\tt options.atol}.
               ({\tt options.ctest}$ = ${\tt 3} only). 
\item{\tt 3 }  An estimate of {\tt cond($\bar{A}$)} has exceeded
               {\tt options.conlim}. The system $Ax = b$ appears to be
               ill-conditioned, or there could be an error in the products 
               with $A$, $A^T$, $P$, or $P^T$. ({\tt options.ctest}$ = ${\tt 3}
               only). 
\item{\tt 4 }  $\|APy - b \|_2$ is small enough for this machine.
               ({\tt options.ctest}$ = ${\tt 3} only). 
\item{\tt 5 }  The least-squares solution is good enough for this
               machine. ({\tt options.ctest}$ = ${\tt 3} only). 
\item{\tt 6 }  The estimate {\tt inform.condAP} appears to be too large 
               for this machine.         
               ({\tt options.ctest}$ = ${\tt 3} only). 
\item{\tt 7 }  The iteration limit {\tt options.itnlim} has been reached. 
\item{\tt 8 }  An array allocation failed.
\item{\tt 9 }  An array deallocation failed.
\item{\tt 10 } Either  {\tt m$<$0} or {\tt n$<$0} (first call only).

\end{description}

\section{Method} \label{method}

\subsection{Algorithm}
The method used is based on the Golub-Kahan bidiagonalization process. 
It is algebraically equivalent to applying MINRES to the normal 
equation $(A^TA+\lambda^2I)x=A^Tb$ (or $((AP)^T(AP)+\lambda^2I)y=(AP)^Tb$,
$Py = x$,
if preconditioning is used), but has better numerical properties, 
especially if $A$ is ill-conditioned. 
Full details may be found in
{\url{
http://web.stanford.edu/group/SOL/software/lsmr/LSMR-SISC-2011.pdf}}.

\subsection{Scaling}
     LSMR uses an iterative method to approximate the solution.
     The number of iterations required to reach a certain accuracy
     depends strongly on the scaling of the problem.  Poor scaling of
     the rows or columns of $A $ should therefore be avoided where
     possible. For example, in problem 1 the solution is unaltered by
     row-scaling.  If a row of $A$ is very small or large compared to
     the other rows of $A$, the corresponding row of $ ( A\;  b )$ should be
     scaled up or down.
    
     In problems 1 and 2, the solution $x$ is easily recovered
     following column-scaling.  Unless better information is known,
     the nonzero columns of $A$ should be scaled so that they all have
     the same Euclidean norm (e.g., 1.0).
     In problem 3, there is no freedom to re-scale if damp is
     nonzero.  However, the value of {\tt damp} should be assigned only
     after attention has been paid to the scaling of $A$.
    
     The parameter {\tt damp} is intended to help regularize
     ill-conditioned systems, by preventing the true solution from
     being very large.  Another aid to regularization is provided by
     the {\tt inform.condAP}, which may be used to terminate iterations
     before the computed solution becomes very large.

\subsection{Initial estimate}
    
     Note that $x$ (or $y$ for the preconditioned problem) is not an input
     parameter.
     If some initial estimate $x_0$ of $x$ is known and if $\lambda = 0$,
     one could proceed as follows:
    \begin{itemize} 
     \item 1. Compute a residual vector     $r_0 = b - Ax_0$.
    \item 2. Use LSMR to solve the system  $A \delta x = r_0$.
    \item 3. Add the correction $\delta x$ to obtain a final solution $x = x_0 + \delta x$.
    \end{itemize}
     This can be generalized for the preconditioned case.
     The guess $x_0$ has to be available before and after the calls
     to {\tt spral\_lsmr()}.  To judge the benefits, suppose {\tt spral\_lsmr()} takes $k_1$ iterations
     to solve $Ax = b$ and $k_2$ iterations to solve $A \delta x = r_0$.
     If $x_0$ is ``good", $\|r_0\|_2$ will be smaller than $\|b\|_2$.
     If the same stopping tolerances {\tt options.atol} and {\tt options.btol}
      are used for each
     system, $k_1$ and $k_2$ will be similar, but the final solution $x = x_0 + \delta x$
     should be more accurate.  The only way to reduce the total work
     is to use a larger stopping tolerance for the second system.
     If some value {\tt options.btol} is suitable for $Ax=b$, the larger value
     {\tt options.btol}*$\|b\|_2$/$\|r_0\|_2$  should be suitable for $A \delta x = r_0$.
    



%%%%%%%%%%%%%%%%%%%%%% EXAMPLE %%%%%%%%%%%%%%%%%%%%%%%%

\section{Example}
The following code illustrates the use of LMSR

\verbatiminput{examples/C/lsmr.c}

This returns the following output:

\begin{verbatim}
Exit LSMR with inform.flag = 2 and inform.itn = 3
LS solution is:
       0.18       0.26       0.17
\end{verbatim}

\begin{funders}
   \funder{epsrc}{Funded by EPSRC grant EP/MO25179/1}
\end{funders}
